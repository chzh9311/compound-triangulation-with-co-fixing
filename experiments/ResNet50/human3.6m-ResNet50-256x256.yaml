DATASET:
  NAME: human3.6m
  ROOT: /home/chenzhuo/data/h36m-fetch/processed
  LABELS: /home/chenzhuo/data/h36m-fetch/extra/human36m-multiview-labels-GTbboxes.npy
  MONOLABELS: data/h36m/labels/human36m-monocular-labels-GTbboxes.npy
MODEL:
  STYLE: "pytorch"
  SOFTMAX_BETA: 100
  SAMPLE_LEVEL: 2
  IMAGE_SIZE:
    - 256
    - 256
  NUM_JOINTS: 17
  NUM_BONES: 16
  INIT_WEIGHTS: True
  LOAD_FINAL_WEIGHTS: True
  PRETRAINED: pretrained/pytorch/pose_mpii/pose_resnet_50_256x256.pth.tar
#  BACKBONE_WEIGHTS: log/remote/Training_vanishing_mu/best.pth
#  BACKBONE_WEIGHTS: log/backbone/Training_NoDensityHM_human3.6m_ResNet50/weights/best.pth
  BACKBONE_WEIGHTS: log/remote/sidenet/best.pth
#  BACKBONE_WEIGHTS: pretrained/pytorch/sidenet/pretrained_ResNet50.pth

  # The method to regress density map:
  # 1. 'direct' means directly regress heatmap using simple regression module;
  # 2. 'heatmap2d' means output 2d heatmap and regress mathematically.
  # 3. 'heatmap1d' means output 1d heatmap and regress.
  # 4. 'offsetmap' refers to vector field that points to the vanishing point.
  # None for pure joint estimations.
  DENSITY_REG_METHOD: multilayer

  EXTRA:
    SIGMA: 2
    HEATMAP_SIZE:
      - 64
      - 64
    FINAL_CONV_KERNEL: 1
    DECONV_WITH_BIAS: False
    NUM_DECONV_LAYERS: 3
    NUM_DECONV_FILTERS:
      - 256
      - 256
      - 256
    NUM_DECONV_KERNELS:
      - 4
      - 4
      - 4
    NUM_LAYERS: 50

  direct:
    # For direct
    NUM_REFINE: 2
    # For heatmap1d

  multilayer:
    NUM_REFINE: 2
    FREEZE_BACKBONE: True
    LAYER_SIZE_MULTIPLIER: 1
    CONFIDENCE: True

  heatmap2d:
    REG_METHOD: linear # linear or exp
    ALPHA: 0.001
    N_SAMPLES: 16
    OFFSET: 0.00001

  heatmap1d:
    DENSITY_SIZE: 64

  offsetmap:
    SAMPLE_LEN: 64
    # offsetmap type values:
    # lambda: -1 ~ 0 ~ 1 => 0 ~ +inf ~ -inf ~ 0.
    # mu: 0 ~ 1 => 0 ~ +inf but the vanishing point can be in the opposite direction.
    TYPE: mu
    FINAL_CONV_KERNEL: 1
    DECONV_WITH_BIAS: False
    NUM_DECONV_LAYERS: 3
    NUM_DECONV_FILTERS: # Larget Deconvlutional layers.
      - 512
      - 512
      - 512
    NUM_DECONV_KERNELS:
      - 4
      - 4
      - 4


TRAIN:
  IS_PRETRAIN: True
  BATCH_SIZE: 32
  LEARNING_RATE: 0.0001
  SHUFFLE: True
  NUM_WORKERS: 16
  NUM_EPOCHS: 10
  CONTINUE: False
  CHECKPOINT: None

TEST:
  WRITE_LOG: False
  BATCH_SIZE: 32
  DATA_PARALLEL: True
  USE_GT_DATA_TYPE:
  LAMBDA: 50000
  # di / mu / op
  FUSION_STRATEGY: maha
  SHUFFLE: True
  NUM_WORKERS: 8
